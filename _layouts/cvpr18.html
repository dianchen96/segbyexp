<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<link rel="StyleSheet" href="css/style.css" type="text/css" media="all" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>Learning Instance Segmentation by Experimentation</title>
<style type="text/css">
#primarycontent h1 {
  font-variant: small-caps;
}
#primarycontent h3 {
}
#primarycontent teasertext {
  text-align: center;
}
#primarycontent p {
  text-align: center;
}
#primarycontent {
  text-align: justify;
}
#primarycontent p {
  text-align: justify;
  padding-left: 10px;
  padding-right: 10px;
}
#primarycontent p iframe {
  text-align: center;
}
.featart {
  margin:4px;
}
.hoverdiv {
  background-color:black;
  margin-top:2px;
  margin-bottom:10px;
  width:100%;
}
.hoverdiv:hover {
  background-color:white;
}
</style>

<script type="text/javascript">
  function togglevis(elid){
    el=document.getElementById(elid);
    aelid=elid+"a";
    ael=document.getElementById(aelid);
    if(el.style.display=='none'){
      el.style.display='inline-table';
      ael.innerHTML="[Hide BibTex]";
    }else{
      el.style.display='none';
      ael.innerHTML="[Show BibTex]";
    }
  }
</script>
<script type="text/javascript"
  src="http://www.maths.nottingham.ac.uk/personal/drw/LaTeXMathML.js">
</script>
<!--
<script type="text/javascript" src="http://math.etsu.edu/LaTeXMathML/LaTeXMathML.js"></script>
<link rel="stylesheet" type="text/css" href="http://math.etsu.edu/LaTeXMathML/LaTeXMathML.standardarticle.css" />
-->

<script>
	 (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	 (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

		ga('create', 'UA-93210824-1', 'auto');
		ga('send', 'pageview');
</script>

</head>
<body>
<div id="primarycontent">
<h1 align="center" itemprop="name"><strong>Learning Instance Segmentation by Experimentation<br />for Vision-Based Rope Manipulation</strong></h1>

<center>
<ul id="people">
	<h2>In Submission to CVPR 2018</h2>
</ul>
</center>

<center><img src="cvpr18.jpg" itemprop="image" width="600" alt="teaserImage"></center>

<h3>Abstract</h3>
<p>We present a robotic system that learns to segment its visual observations into individual objects by experimentingwith its environment in a completely self-supervised manner. The robot maintains a belief about what group of pixelsconstitute an object and refines its belief by interacting withpixels it believes to constitute an object. Our system makesover 50K interactions with the environment while improvingits learned segmentation model in the process. The learnedmodel generalizes to novel objects and backgrounds.  Oursystem is at par with the performance of a strongly super-vised instance segmentation model which was trained over 700K manually labeled images in COCO and pretrained on 1M Imagenet data when evaluated on the heldout test set. We provide evidence that re-organization of visual obser-vations into objects is a powerful representation for downstream vision based control tasks. Our system is capable ofrearranging multiple objects into target configurations fromvisual inputs alone.
</p>


<h3>Video</h3>
<table style="margin: 0 auto">
  <tr>
  <p style="padding-left: 10px; padding-right: 10px;">
  This video explains our method and shows some of our experimental results.
  </p>
    <td>
     <iframe width="800" height="480" src="https://www.youtube.com/embed/lVmN6LcQwDU" frameborder="0" allowfullscreen></iframe>
    </td>
  </tr>
</table>

<h3 style="clear:both">Website Template</h3>
<p style="padding-left: 10px; padding-right: 10px;">
The template for this website has been adopted from Carl Doersch.
</p>

<!-- <h3 style="clear:both">Contact</h3> -->
<!-- <p style="padding-left: 10px; padding-right: 10px;">
For comments/questions, contact <a href="http://people.eecs.berkeley.edu/~pathak/">Deepak Pathak</a></p> -->
</div>

</body>
</html>